%----------------------------------------------------------------------------
\chapter{Experimental results}\label{chap:Tests}
%----------------------------------------------------------------------------
In the following chapter the results of the system tests will be discussed. 
The speed and precision of the operation and the accuracy of the classification were tested using a set of diverse test videos.

The results are revised and analysed with various parameter settings.
A method to correct the errors caused by the miscalibration of the test videos is proposed as well.
Lastly, the proper operation speed is ensured by testing the performance of the application on the target hardware.

\section{Test videos}\label{sec:test_videos}
For testing purposes a set of test videos, that capture miscellaneous urban scenes, are used.
The videos were recorded at multiple places in Budapest.
To ensure the robustness of the application, they represent diverse weather, light and traffic conditions, including heavy shadows, night-time, dawn, sundown, and various traffic densities and road users.
The attributes of the test videos are presented in detail in table \ref{tab:test_videos}.

\begin{table}[!h]
	\begin{adjustbox}{center}
		\includetable{test_videos}
	\end{adjustbox}
	\caption{Characteristics of videos used for performance testing.}
	\label{tab:test_videos}
\end{table}

Besides the traffic and light conditions, in which the videos were recorded, table \ref{tab:test_videos}.~presents other important characteristics and specific settings, that determine the evaluation's quality and level of detail.

The "Lanes set" option specifies whether the centre of lanes are defined in the configuration files, as an initial setting for the video.
If it is, the parameter calculation is limited to these specified lane-regions on the Tripwire, that increases the operation speed.
However it affects the precision of classification as well, because the average length value is calculated from less samples.

The point count of the video's ground truth sets the resolution of the precision measures.

Other, video-specific settings are also presented, when appropriate.
The higher sensitivity of MOG2 overreaction is required for shadow-dense streams, where light changes can easily overwhelm the background-subtractor.
A minimal blob size (minSize), smaller than the default setting is specified, whenever the possibility of smaller road-users (e.g. pedestrians, cyclists) is higher, to be able to detect them more precisely.
The corrected calibration feature means higher precision and accuracy values for the video, but does not influence the effect of changing other settings. 
\FloatBarrier

%----------------------------------------------------------------------------
\section{Evaluation results}
%----------------------------------------------------------------------------
This section presents the results of the evaluation of the measures described in section \ref{chap:evaluation}.
The values were quantified using five different parameter-setting, each case specified to eliminate a specific, prevalent error cause.

\subsection{Versions of test settings}
The various settings used for testing are seen in table \ref{tab:settings_versions}.
Although, the application uses several configuration parameters, in this section only the ones, that were modified between two evaluation session, are discussed.

As mentioned before (in section \ref{subs:ProjectConfigurator}.), each video has specific parameters, depending on the environment characteristics.
The particular values of these parameters were evaluated empirically for each video, to give the best results possible, and is not discussed in this work.

\begin{table}[!h]
	\begin{adjustbox}{center}
		\includetable{versions_settings}
	\end{adjustbox}
	\caption{The settings at each testing session. If not defined, the minimal cutting size equals the minimal size.}
	\label{tab:settings_versions}
\end{table}

The modified parameters are as follows
\begin{enumerate}
	\item \textbf{minimal size of blobs:} Although the system detects blobs from all sizes, only the ones exceeding the size limit are accepted as vehicles. If the minimal size decreases, the number of both false negatives and positives increases, since more fake and real vehicles are detected.
	
	\item \textbf{lane centres defined or not:} The reason lane centres are specified is detailed in section \ref{sec:test_videos}. Depending on the traffic scene, lane centres cannot be set for every video (table \ref{tab:test_videos}), thus are not initially configured for some of them. Consequently the evaluation results of certain videos are not affected by this parameter change. As described before, lane settings influence the result of classification, and the speed of the operation.
	
	\item \textbf{minimal size for cutting:} Specifies the minimal size of split blobs. The method of blob splitting is presented in section \ref{sec:background-subtraction}., and is used to divide fused vehicles, that cross the Tripwire together. If the resulting blobs are of a smaller size than the limit, the splitting is cancelled, and the blob is stored as a whole. The optimal minimal split size is smaller than the regular minimal blob size, since due to the perspective, the fused vehicles can cover parts of each other, as seen on figure \ref{fig:cover_vehicles}. If the parameter value equals the minimal size, some fused vehicles are missed, although, when set to a very low value, the number of false splitting, thus the number of false detections can increase.
\end{enumerate}

\subsection{Results}

\subsubsection{Initial setting}
- minSize: 250
- lanes: defined for most videos

\subsubsection{Minimal size of blobs redefined}
- minSize: 200
- lanes: defined for most videos

\subsubsection{No lanes defined}
- minSize: 200
- lanes: no lanes

\subsubsection{Split size added}
- minSize: 100
- splitMinSize : 200

\begin{figure}[p]
	\centering
	\includechart{recalls}
	\caption{Recalls}
\end{figure}

\begin{figure}[p]
	\centering
	\includechart{accuracies}
	\caption{Accuracies}
\end{figure}

\begin{figure}[p]
	\centering
	\includechart{typerecalls}
	\caption{Type recalls}
\end{figure}

\begin{figure}[p]
	\centering
	\includechart{falsePositives}
	\caption{False positives}
\end{figure}

\begin{figure}[p]
	\centering
	\includechart{falseNegatives}
	\caption{False negatives}
\end{figure}

\subsubsection{Split size final setting}

\subsection{Common errors and solutions}
\subsubsection{False positives}
\subsubsection{False negatives}
\subsubsection{Misclassification errors}

%----------------------------------------------------------------------------
\section{Calibration correction}\label{chap:cal_corr}
%----------------------------------------------------------------------------
Due to perspective transform, vehicle lengths on frames decrease as moving away from the camera.
Since vehicle lengths are the basis of classification, to measure it precisely, perspective distortion needs to be eliminated.
The compensation of distortion is performed during the preprocessing phase of the Traffic Sensor operation, using a quadrangle-based compensation method.

The quadrangle, called the calibration rectangle, is manually defined by the user.
It is hand-drawn on a frame in the Project Configurator GUI (section \ref{chap:calibration}.) as part of the calibration process.
The position and the sides' lengths are estimated with the help of any occurring road lanes, or simply based on naked eye examination.
On this wise, due to the inaccuracy of human perception, the location and size of the calibration rectangle are significantly uncertain.
Empirical analysis shows that errors are actually present in many hand-calibrated videos.

To avoid manual calibration, some traffic surveillance systems automatize this process.
However in heterogeneous environment, it is a highly complex problem, and is not implemented in the current version of the Traffic Sensor system, still the existing settings can be corrected.

To evaluate the degree of miscalibration, lengths of the vehicles are examined as a function of distance from the camera.
After, during the finishing steps of the processing, the calibration rectangle is redefined for later use.
To eliminate false detections of miscalibration, the proposed corrections are revised and optionally affirmed by the user or the developer.

In the following section, the process of calibration, its correction method, and the experimental results of the improvement of calibration are detailed.

\subsection{The miscalibration problem}
\subsubsection{Perspective compensation method}
The calibration rectangle is constructed by defining its four edges from the upper left corner, to the lower left one in order.
The edges must be coplanar in the plane of the street, and correspond to those of a square's in the 3-dimensional (3D) world.
The square, due to the perspective transformation, converts to a general quadrilateral on the image plane.
On most videos, lane markings, that are parallel lines on the road, are used to find and define the required edges.
The length of the rectangle's sides are approximated and set by the user as well.

The four vertices are then projected back into a square, along with the entire pixel grid of the image using a transformation map to speed up the process.
Examples of the Frames, before and after the perspective compensation transformation, are seen in figure \ref{fig:perscomp}.
For defining the transform and constructing the map, universal OpenCV methods were used \cite{PersTrans, WrapPers}.

\begin{figure}[!t]
	\centering
		\begin{subfigure}[b]{0.4\textwidth}
			\includegraphics[width=\textwidth]{raw_frame_ibike.png}
			\caption{A Raw Frame from the ErE5 video sequence.}
		\end{subfigure}
		\quad
		\begin{subfigure}[b]{0.4\textwidth}
			\includegraphics[width=\textwidth]{original_frame_ibike.png}
			\caption{An Original Frame from the ErE5 video sequence.}
		\end{subfigure}
		\hfill
		\begin{subfigure}[b]{0.4\textwidth}
			\includegraphics[width=\textwidth]{raw_frame_fovam.png}
			\caption{A Raw Frame from the FovamC\_D video sequence.}
		\end{subfigure}
		\quad
		\begin{subfigure}[b]{0.4\textwidth}
			\includegraphics[width=\textwidth]{original_frame_fovam.png}
			\caption{An Original Frame from the FovamC\_D video sequence.}
		\end{subfigure}
		
		\caption{Frames before and after the perspective compensation. The calibration rectangle's edges are marked with their sequential numbers.\label{fig:perscomp}}
\end{figure}

In the output images of the transform -- the Original Frame-strip --  vehicle lengths are independent of the vehicle's position in the image. 

The calibration rectangle's side length is used to define a scaling factor between the 3D world and the image plane as well.
Using the scaling factor, all lengths are converted to a metric scale, facilitating correct classification.

\subsubsection{Miscalibrated streams}
If the calibration rectangle's edges are significantly displaced from those of a perfect coplanar square in the 3D world, the ensuing miscalibration considerably influences the accuracy of the classification results.
To detect whether this problem occurs, vehicle lengths are analysed along the tripwire.

\begin{figure}[!t]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\centering
		\begin{subfigure}[t]{0.45\textwidth}
		\includegraphics[width=\textwidth]{FovamC_raw_frame_uncalib.png}
		\end{subfigure}
	\quad
		\begin{subfigure}[t]{0.375\textwidth}
		\includegraphics[width=\textwidth]{FovamC_uncalibrated_example.png}
		\end{subfigure}
	\subcaption{Uncalibrated.\label{sfig:uncalib}}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{\textwidth}
		\centering
		\begin{subfigure}[t]{0.45\textwidth}
			\includegraphics[width=\textwidth]{FovamC_mcalib.png}
		\end{subfigure}
		\quad
		\begin{subfigure}[t]{0.375\textwidth}
			\includegraphics[width=\textwidth]{FovamC_miscalib.png}
		\end{subfigure}
		\subcaption{Miscalibrated. \label{sfig:mcalib}}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{\textwidth}
		\centering
		\begin{subfigure}[t]{0.45\textwidth}
			\includegraphics[width=\textwidth]{FovamC_ccalib_frame.png}
		\end{subfigure}
		\quad
		\begin{subfigure}[t]{0.375\textwidth}
			\includegraphics[width=\textwidth]{FovamC_ccalib.png}
		\end{subfigure}
		\subcaption{Correctly calibrated.}
	\end{subfigure}

	\caption{Frame setting and average vehicle lengths along the Tripwire on the FovamC\_D video sequence, when the video is uncalibrated, miscalibrated and correctly calibrated. The tripwire is drawn with red. Some vehicle lengths are marked to show the difference in distance from the camera. On the correctly calibrated frame the lengths are approximately the same. The light blue line indicates the estimated slope of the length values.\label{fig:calibration_versions}}
\end{figure}

An uncalibrated stream is characterized by the decrease of vehicle lengths as moving away from the camera, due to perspective distortion, as seen on figure \ref{sfig:uncalib}.
If the lengths still decrease despite that perspective compensation was performed, there is a high chance of inaccurate calibration (an example is seen in figure \ref{sfig:mcalib}.), when perspective distortion was not compensated well.
Nonetheless, some exceptions may occur, especially with a walking route and a bicycle track adjacent to the road, where the typical road users are of smaller size.

To accurately estimate the mean size of road users along a line, a considerably long video sequence is analysed to count enough vehicles for averaging.
The proper video length was empirically approximated to be at least 6000-frame long.

\subsection{The calibration correction method}
In the following section, the method, proposed to correct the erroneous calibration, is presented.

The three stages of the correction process are as follows:
\begin{enumerate}
\item At the first step, a line is fitted to the vehicle length data using linear regression.
\item Next, the average lengths at the two sides of the calibration rectangle are calculated from the parameters of the approximated line.
\item Last, a the ratio of these sizes are used to reshape the sides of the calibration rectangle.
\end{enumerate}

\noindent The calibration correction steps are detailed as follows:
\begin{enumerate}[align=parleft]
	\item  \textbf{Line estimation:} 
	Calibration correction is performed in single-run mode (section \ref{chap:operation_modes}), after the entire length of the video is processed.
	During the detection phase, in each point of the Tripwire, the average vehicle lengths are iteratively recalculated with the newly computed size values of the Size Timeline.
	The result of the calculation can then be visualized (as presented in section \ref{sec:data_representation}) as a curve of vehicle sizes as a function of position on the Tripwire.
	For quantifying the degree of the decrease in lengths, a line is fitted to the data set with simple least square approximation.
	The parameters of the fitted line ($fl(k)$) are stored.
	If the line is only slightly sloped, average lengths curve is approximately constant, thus there is no need for calibration correction. 
	
	\item  \textbf{Size ratio calculation:}
	First, the intersections of the Tripwire and the side lines of the calibration rectangle ($\boldsymbol{T}(K_{\text{CR}}), \boldsymbol{T}(k_{\text{CR}})$) are approximated.
	(Here, $k_{\text{CR}}$ and $K_{\text{CR}}$ denotes the intersection points' positions on the Tripwire in pixels.)
	
	Since the Traffic Sensor is placed on the side of the road, the typical frame scenery is customarily similar to the one seen on figure \ref{sfig:uncalib}.
	The calibration rectangle has two sides ($s_{\text{CR}}$ and $S_{\text{CR}}c$) roughly perpendicular to the Tripwire.
	Due to perspective transform, these perpendicular sides are subject to perspective distortion, thus differ in length, namely the top side of the rectangle is considerably shorter, as well as vehicle sizes at this distance.
	
	If the video is undercalibrated, the rectangle sides' difference is too small, so that after the perspective compensation, average vehicle sizes are still significantly smaller at the top side of the rectangle (an example is seen on figure \ref{sfig:mcalib}.).
	To diagnose this problem, the size values at the intersections are calculated using the fitted line:
	\begin{gather*}
		l = fl(k_{\text{CR}}) \approx \avgt\{\boldsymbol{TI_{\text{Size}}}(\boldsymbol{T}(k_{\text{CR}}))\} \\
		L = fl(K_{\text{CR}}) \approx \avgt\{\boldsymbol{TI_{\text{Size}}}(\boldsymbol{T}(K_{\text{CR}}))\},
	\end{gather*}
	
	with $fl(k_{\text{CR}}), fl(K_{\text{CR}})$ being the length values of the fitted line in the intersection points ($k_{\text{CR}}$ and $K_{\text{CR}}$) of the Tripwire.
	These length values correspond to the mean values of the length data stored in the proper rows of the Size Timeline.
	 
	After, the ratio of these two lengths is calculated, quantifying the degree of miscalibration, $r$:
	\begin{displaymath}
		r = \frac{L}{l}.
	\end{displaymath}
	
	The notations used above are illustrated in figure \ref{fig:ratio_calculation}.
	
	\item  \textbf{Rectangle correction:}
	After the ratio of the lengths are calculated, the longer side of the calibration rectangle, $S_{\text{CR}}$ is resized.
	Its length is multiplied with the ratio $r$ to produce the corrected length $S_{\text{CR,corr}}$.
	 To fit the new value, the side is expanded equally in both directions as seen on figure \ref{fig:resizing_cr}. 
	The numbering of edges stay consistent.
	After resizing, the length of the sides are re-evaluated as well.
\end{enumerate}

\begin{figure}[!h]
	\centering
	\includesvg[width=0.9\textwidth]{configuration_correction}
	\caption{Notation used in calibration correction, and the ratio calculation step of the process. The sizes at intersection of the Tripwire with the two intersecting calibration rectangle sides are evaluated, and the ratio of these length values are calculated. \label{fig:ratio_calculation}}
\end{figure}

\begin{figure}[!h]
	\centering
	\includesvg[width=0.4\textwidth,pretex=\relsize{1.5}]{resizing_of_cr}
	\caption{The resizing of the calibration rectangle. The larger side's length is multiplied with the ratio, $r$, and the side is expanded at each edges to fit the new value. All other sides are repositioned to fit the newly computed edges. \label{fig:resizing_cr}}
\end{figure}

\subsection{Calibration correction results}
The results of miscalibration are presented using four test videos (an overview of the test videos is found in section \ref{sec:test_videos}.), that were initially miscalibrated.

The quantitative evaluation results before and after the calibration correction are summarized in table \ref{tab:cal_corr_results}.
Three of four videos were tested with and without lanes defined.
Each video's type recall measures improved both with and without lanes defined. 
This is due to the the correct perspective compensation, resulting in correct lengths of vehicles.

Average vehicle sizes along the Tripwire for all four videos before and after correction are seen in figure \ref{fig:calibrations2}.
In each case, the length curves are more balanced after the correction.

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{center}
	\includetable{cal_corr_table}
\end{adjustbox}
	\caption{Table detailing the results of evaluation before and after calibration correction. Independently from lanes, the type recall of all videos improved after the correction. This is due to more realistic length measurements. The accuracy of some videos, including GoldA2 or GoldB1 (whithout lanes) have decreased due to the increase of false detections (increased false positive count). This is a result of expansion of blobs at the far end of the Tripwire, that, including the ones caused by noise, are not getting filtered. All measures are in \%.}
  	\label{tab:cal_corr_results}%
\end{table}%


\clearpage
\addtolength{\topmargin}{-.6in}
\begin{figure}[p]
	\thispagestyle{empty}
	\centering
	\thisfloatpagestyle{empty}
	\begin{subfigure}[t]{0.36\textwidth}
		\includegraphics[width=\textwidth]{calibrationCorrection_GoldA2_Not_OK.png}
		\caption{GoldA2, miscalibrated.}
	\end{subfigure}
	\quad
	\begin{subfigure}[t]{0.36\textwidth}
		\includegraphics[width=\textwidth]{calibrationCorrection_OK_GoldA2.png}
		\caption{GoldA2, corrected.}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.36\textwidth}
		\includegraphics[width=\textwidth]{calibrationCorrection_Fovam_not_OK.png}
		\caption{FovamC\_D, miscalibrated.}
	\end{subfigure}
	\quad
	\begin{subfigure}[t]{0.36\textwidth}
		\includegraphics[width=\textwidth]{calibrationCorrection_Fovam_OK.png}
		\caption{FovamC\_D, corrected.}
	\end{subfigure}
\hfill
\begin{subfigure}[t]{0.36\textwidth}
	\includegraphics[width=\textwidth]{calibrationCorrection_OK_SasA1_Med.png}
	\caption{SasA1, miscalibrated.}
\end{subfigure}
\quad
\begin{subfigure}[t]{0.36\textwidth}
	\includegraphics[width=\textwidth]{calibrationCorrection_not_OK_SasA1_Med.png}
	\caption{SasA1, corrected.}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.36\textwidth}
	\includegraphics[width=\textwidth]{calibrationCorrection_not_OK_GoldB1_Sun.png}
	\caption{GoldB1, miscalibrated.}
\end{subfigure}
\quad
\begin{subfigure}[t]{0.36\textwidth}
	\includegraphics[width=\textwidth]{calibrationCorrection_OK_GoldB1_Sun.png}
	\caption{GoldB1, corrected.}
\end{subfigure}
	\caption{Average vehicle lengths along the Tripwire calculated from a the same Frame-strip before and after calibration correction. After the correction, average sizes are distributed uniformly along the Tripwire.(The light blue line indicates the estimated slope of the length values.)\label{fig:calibrations2}}
\end{figure}

\clearpage
\addtolength{\topmargin}{+.6in}
%----------------------------------------------------------------------------
\section{Results of speed tests}
%----------------------------------------------------------------------------
Since the application is required to operate in real-time, it must meet strict speed criteria.
To not miss certain frames and consequently, vehicles, the software's frame request rate should exceed the camera's capture frequency most of the time.
Along these lines, the minimal recommended processing rate of frames on the target hardware is \SI{25}{frame/s}, considering that most cameras operate around this speed.

However, the optimal required operation speed of the Sensor is higher, \SI{30}{frame/s}, that even allows the integration of new functions, processing steps, or improving existing ones; especially, possible new features, that include highly resource-intensive algorithms, such as a shadow-detection processor (further discussion about shadow detection attempt is found in the work of Istv{\'a}n Vincze \cite{Vincze2016}), or a more sophisticated classifier.

The performance test were all conducted on the target hardware.

The results of speed-testing are seen in table \ref{tab:speed_testing}.

\begin{table}[htbp]
	\centering
	\begin{adjustbox}{center}
		\includetable{speed_results}
	\end{adjustbox}
	\caption{The speed performance of the Traffic Sensor software on the target hardware using test videos.}
	\label{tab:speed_testing}%
\end{table}%

As the results show, although the average operation speed depends on the traffic characteristics, in most situations, it exceeds the specified \SI{25}{frame/s} limit.
Exceptions are the GoldB2 and the SasA2 videos, that feature scenes with very heavy traffic and several stopping vehicles.

Considering the variance of the scenes, most videos still mainly perform over the minimum.
Although at certain times they are likely to fall below the speed floor, the performance rate is acceptable.
