%----------------------------------------------------------------------------
\chapter*{Introduction}\addcontentsline{toc}{chapter}{Introduction}
%----------------------------------------------------------------------------
\section{Traffic load estimation}
%----------------------------------------------------------------------------
In recent years, there has been an increased scope for the automatic analysis of urban traffic activity\cite{Buch2011}.
This case is due to the increasing number of vehicles, the need for better understanding traffic dynamics for investment purposes, and also the accessibility of various sensors.
Formerly traffic estimation was performed by operators, by the means of on-the-spot observation or video analysis.
By the automation of these processes the main concept of traffic analysis is to aid or fully avoid these human operators.

The information obtained by traffic monitoring systems are widely used to regulate traffic flow and contribute to administrative decisions about transportation infrastructure development, maintenance and investments \cite{MagyarKozut}.
In addition to the detection and classification of road users, which is an elementary task, several other monitoring objectives can be supported. 
Typical traffic data such as flow, density, and average speed can be extracted.
Some systems also recognize various situations including traffic violations or accidents (e.g., cars, motorbikes, and pedestrians).
Other real-time applications notify users about congestions, roadworks and accidents, or control traffic lights in order to influence traffic flow direction \cite{AzoSensor, Thiruverahan2015, Ghazal2016}.
It is also possible to estimate environmental measures such as greenhouse gases, pollutant emissions, and fuel consumption in real time using high-resolution video traffic data combined with instantaneous emission models\cite{Morris2012a}. 
In the long term surveillance systems will be integral parts of the smart city infrastructure, identifying and influencing these city's traffic dynamics\cite{enLight}.

\subsection{Traffic monitoring techniques}
Nowadays a variety of sensing modalities is available for on-road vehicle detection.

Inductive loop systems installed in the road are considered the most reliable traffic classification and detection method available, larger metal objects can be accurately detected this way. 
On the other hand, the installation and maintenance is time-consuming and difficult, and slow or temporarily stopped vehicles cannot be detected\cite{Diamond, Zhang2016}.

Other active detection methods, including radar \cite{DeepBlue}, infrared\cite{Swarco, Hussain1995, Ghazal2016} and laser\cite{SICK, Gallego2009} sensors, are also popular owing to their robustness, although a complex machinery needs to be deployed.

Weight-based classification and speed detection is also possible using a piezoelectric sensor\cite{Te, Rivas2017}.

Video cameras have been installed for a long time for traffic monitoring purposes, because they provide a rich information source for human understanding with a relatively low cost of deployment\cite{Tian2011, Buch2011, VideoSurveillance, LaSemaforica}.
Nowadays cameras became even cheaper, smaller, and of higher quality than ever before, and vision-based surveillance is becoming the most popular form of vehicle detection.
In contradistinction to active sensors, cameras provide a wide field of view, allowing for detection across multiple lanes. 
Vision also integrates well with active sensor suites.
The drawbacks to vision-based vehicle detection include sensitivity to light and weather conditions and increased computational cost\cite{Shivaraman2013}.

Multi-modal suites use sensor fusion to combine the data that results from the approaches outlined above\cite{Swarco}.

\subsubsection{Real-time vision sensors}
Although most vision sensor networks use a digital backend system where the captured data is transferred, and computation and storage takes place, since computing power has dramatically increased in the recent years, a new generation of visual surveillance systems has emerged.
These embedded sensors are capable of on-board high-level video processing with limited resources for computation, memory and power \cite{Bramberger2004}.
These platforms have the ability to reliably detect and track on-road vehicles in real time, since they utilize the new image-processing paradigms and advanced hardware: parallelization, multi-core processing and graphical processing units (GPUs)\cite{Sivaraman2013}.
Although the embedded platforms can provide sufficient computing performance, efficiently developing and porting software for these platforms is still a difficult and tedious task\cite{Bramberger2004}.
In this thesis an efficient traffic estimation method for embedded hardware is proposed, which can operate in real time for extended periods.
The implementation and realization details are proposed in the following chapters.

\subsection{Some results in video-based traffic monitoring}
Even though diverse solutions has been suggested in the literature for vision-based surveillance problems, these methods are similar in the fact that they utilize the high information-content of the video stream, whilst the useless data are being identified and omitted for speed purposes.

This section is continued by discussing approaches in monocular vision for on-road traffic monitoring.

Most vehicle counting methods are composed of three levels of perception: detection, tracking and behaviour understanding.

At the first level, the goal is to tell vehicles apart from the background using distinctive features: motion or appearance.

On of the two main approaches is appearance-based selection, where basic image characteristics such as color\cite{Chang2005}, edges\cite{Blanc2007}, symmetry\cite{Aytekin2010}, HOG\cite{TehraniNiknejad2012}, Haar-like\cite{Sivaraman2012}, Gabor\cite{Zhang2006}, SIFT\cite{Zhang2011} or SURF\cite{Lin2012} features are used to identify vehicles.
These detection methods are both applicable for moving and stationary objects or cameras, but requires prior information about foreground object appearances.

Motion-based vehicle detection has been less common than appearance-based methods.
The core idea is to separate moving foreground from motionless background.
This approach relies on background subtraction: the static scene is estimated with various models and moving object are separated accordingly.
Several filters have been proposed for background subtraction, including frame differencing\cite{Park2007}, averaging\cite{Kanhere2008}, graph cuts\cite{Woodford2009}, as well as more sophisticated background models, such as Single Gaussian\cite{Kumar2003}, mode estimation\cite{Zheng2006}, Kalman-filter\cite{Messelodi2005} or wavelets\cite{Gao2009}. 

One of the most common subtraction techniques is Gaussian Mixture Modelling(GMM)\cite{Niknejad2012, Wang2009,Zhang2016a}, where each pixel is temporally modelled as a mixture of two or more Gaussians and is updated online\cite{Stauffer1999,Stauffer2000}.
Although most subtraction techniques assume a fixed scene, GMM can deal with both stationery backgrounds and repetitive changes in light.
The implementation in \cite{Kaewtrakulpong2001} is available in the OpenCV library and is commonly used in research\cite{OpenCVMog2}.

Classification:
The basis of classification is extraction features such as heigh and length\cite{}, linearity feature\cite{}, convex hull of the
silhouette\cite{},

One level up dynamic parameters are measured and the position of road-users is approximated using various tracking algorithms. 
The main purposes of following vehicles across frames is to estimate  motion and predict their positions in the image, enforcing temporal coherence for omitting false positives in counting.
Tracking algorithms range from simplest -- like geometric constraints\cite{Rabe2007}, optical flow\cite{Bhaskar2015}, template matching\cite{Liu2007}, feature-based tracking\cite{Haselhoff2009} -- to most complex, including particle filtering\cite{Danescu2011}, Kalman-filter\cite{Bresson2015}, spatialâ€“temporal Markov random field (S-T MRF)\cite{Zhu2005}, graph correspondence\cite{Lai2010}, event cones\cite{Andrienko2015} along with others. 

The highest level of semantic interpretation lies in characterizing the behaviour of vehicles on the road\cite{Sivaraman2013}.
An aggregate of spatio-temporal features is used to learn, model, classify, and predict the behaviour and goals of other vehicles on the road.
Certain studies try to categorize observed vehicle behavior as normal or abnormal, others 

Automatic license plate recognition is also extensively used\cite{Luvizon2016, Sivaraman2013}. 


Handling extreme weather or light conditions, like rain, thick fog, night-time or heavy shadows is always challenging for visual sensors, therefore a series of different solutions has been proposed to solve these problems.


\subsubsection{Counting vehicles with time-spatial images}
- background substraction methods
- articles: ????

%----------------------------------------------------------------------------
\section{The SOLSUN project}
%----------------------------------------------------------------------------
\subsection{Project goals and constraints}
%precision, speed constraints, SW, HW

%----------------------------------------------------------------------------
\section{Thesis goals and organization}
%----------------------------------------------------------------------------
In this work the operation and structure of the Solsun Traffic Sensor is detailed, in particular with regard to the core software architecture, the hardware environment, network organization and supplementary software elements.
The thesis focuses on the 

This thesis is structured as follows.
The \ref{chap:Concepsts}.~chapter introduces some basic terms and concepts that are essential for understanding the operation of the Traffic Sensor. 
The \ref{chap:Core software}.~chapter presents the structure of the core software side by side with the video processing steps.
In chapter \ref{chap:Environment}.~the supplementary software and hardware elements linking the system together are detailed.
The \ref{chap:Tests}.~chapter details the results of the hardware and software experiments and proposes solutions for the most commonly occurring error cases.
